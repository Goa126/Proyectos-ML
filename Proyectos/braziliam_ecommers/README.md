# üáßüá∑ An√°lisis Integral de E-commerce Brasile√±o (Olist Dataset)

Este proyecto realiza un an√°lisis exhaustivo de datos de comercio electr√≥nico de Olist (2016-2018), abarcando desde la ingenier√≠a de datos y estructuraci√≥n en SQL, hasta el an√°lisis exploratorio, clustering de clientes y modelos predictivos de Machine Learning.

## üöÄ Objetivo del Proyecto
Transformar datos crudos de transacciones, log√≠stica y rese√±as en insights estrat√©gicos para mejorar la experiencia del cliente y la eficiencia operativa. El an√°lisis busca responder preguntas clave sobre **estacionalidad de ventas**, **causas de insatisfacci√≥n** y **segmentaci√≥n de clientes**.

## üìÇ Estructura del Proyecto

```bash
braziliam_ecommers/
‚îú‚îÄ‚îÄ data/                       # Dataset original (archivos CSV de Olist)
‚îú‚îÄ‚îÄ notebooks/                  # Jupyter Notebooks con el an√°lisis y modelado
‚îÇ   ‚îú‚îÄ‚îÄ analisis_series_temporales.ipynb  # EDA, Series Temporales, Clustering y ML Predictivo
‚îÇ   ‚îî‚îÄ‚îÄ sistemas_de_recomendacion.ipynb   # Motores de recomendaci√≥n (Similitud y Cross-Selling)
‚îú‚îÄ‚îÄ sql/                        # Scripts SQL para la base de datos
‚îÇ   ‚îî‚îÄ‚îÄ sql_braziliam.sql       # Schema, PKs, FKs y creaci√≥n de Vistas Anal√≠ticas
‚îú‚îÄ‚îÄ src/                        # C√≥digo fuente modular
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # API REST con FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ save_models.py          # Script de persistencia de modelos
‚îú‚îÄ‚îÄ models/                     # Artefactos de modelos (Archivos .pkl)
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias del proyecto
‚îî‚îÄ‚îÄ .env                        # Variables de entorno (credenciales de BD)
```

## üõ†Ô∏è Tecnolog√≠as Utilizadas
*   **Lenguaje:** Python 3.12+
*   **Base de Datos:** PostgreSQL
*   **Librer√≠as Principales:** `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `sqlalchemy`, `python-dotenv`, `fastapi`, `uvicorn`, `joblib`.

## üìä Flujo de Trabajo y Metodolog√≠a

### 1. Ingenier√≠a de Datos (SQL & PostgreSQL)
*   **Modelado de Datos:** Se estructur√≥ la base de datos relacional definiendo Llaves Primarias (PK) y For√°neas (FK) para garantizar la integridad referencial.
*   **Vistas Anal√≠ticas:** Creaci√≥n de `vista_entrenamiento_ml` y tablas enriquecidas (`ds_enriquecido_ml`) para consolidar informaci√≥n dispersa (pedidos, clientes, productos, pagos y rese√±as) en una √∫nica fuente de verdad para los modelos.

### 2. An√°lisis Exploratorio y Series Temporales
*   **Conexi√≥n Directa:** Integraci√≥n de SQL con Python mediante `SQLAlchemy` para consultas eficientes.
*   **Tendencias Temporales:** Detecci√≥n de patrones de crecimiento org√°nico en 2017 y picos estacionales (Black Friday).
*   **Comportamiento del Usuario:** Identificaci√≥n de horarios "Prime Time" de compra (d√≠as laborales 10:00 - 17:00) y ca√≠da de actividad en fines de semana.

### 3. Segmentaci√≥n de Clientes (Clustering)
Uso de algoritmos no supervisados (**K-Means**) para clasificar la experiencia de entrega en 3 clusters:
*   **Cluster 0 (Problema de Producto):** Entregas r√°pidas pero baja calificaci√≥n (problemas de calidad en Muebles/Telefon√≠a).
*   **Cluster 1 (Riesgo Log√≠stico):** Demoras extremas (>30 d√≠as) y p√©sima calificaci√≥n.
*   **Cluster 2 (Est√°ndar de Oro):** Entregas eficientes y satisfacci√≥n alta.

### 4. Machine Learning: Predicci√≥n de Insatisfacci√≥n
Entrenamiento de un modelo de **Random Forest Classifier** para predecir si un cliente tendr√° una experiencia negativa (Review Score < 3).
*   **Desempe√±o:** Recall del 54% (detecta m√°s de la mitad de las quejas potenciales).
*   **Hallazgos Clave:**
    *   **D√≠as de Entrega Real:** El factor m√°s cr√≠tico.
    *   **Costo del Flete:** Sorpresivamente, un flete caro genera m√°s insatisfacci√≥n que un producto caro.
    *   **Dimensiones:** Productos voluminosos tienen mayor tasa de incidencia.

### 5. Motores de Recomendaci√≥n
Se implementaron dos motores de recomendaci√≥n para atacar diferentes objetivos de negocio:
*   **Modelo 1: Similitud de Productos (Content-Based):** 
    *   Utiliza *Cosine Similarity* para encontrar sustitutos directos basados en categor√≠a, precio y calidad (`review_score`).
    *   Objetivo: Ayudar al usuario a comparar opciones similares.
*   **Modelo 2: Venta Cruzada (Cross-Selling / Association):** 
    *   Analiza la co-ocurrencia de productos en un mismo carrito de compras, filtrando conexiones entre categor√≠as diferentes.
    *   Objetivo: Sugerir complementos l√≥gicos y aumentar el valor del pedido (ej. *Home Comfort* -> *Bed Bath Table*).

### 6. Despliegue de API (FastAPI)
Se desarroll√≥ una API REST para consumir las recomendaciones en tiempo real sin necesidad de recalcular los modelos.
*   **Persistencia:** Los modelos se pre-procesan y serializan mediante `joblib` para una carga instant√°nea.
*   **Endpoints:**
    *   `GET /recomendar/similares/{product_id}`: Retorna top N productos similares.
    *   `GET /recomendar/cruzada/{product_id}`: Retorna productos complementarios (cross-selling).
    *   `GET /docs`: Documentaci√≥n interactiva de la API con Swagger UI.

## ‚öôÔ∏è Instalaci√≥n y Configuraci√≥n

1.  **Clonar el repositorio:**
    ```bash
    git clone <url-del-repositorio>
    cd braziliam_ecommers
    ```

2.  **Crear entorno virtual e instalar dependencias:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

3.  **Configurar Variables de Entorno:**
    Crear un archivo `.env` en la ra√≠z con las credenciales de PostgreSQL:
    ```env
    DB_USER=tu_usuario
    DB_PASSWORD=tu_contrase√±a
    DB_HOST=localhost
    DB_PORT=5432
    DB_NAME=nombre_base_datos
    ```

4.  **Generar Artefactos de Modelos:**
    Para que la API funcione, primero debes generar los archivos `.pkl`:
    ```bash
    python src/save_models.py
    ```

5.  **Iniciar la API:**
    ```bash
    uvicorn src.main:app --reload
    ```
    Accede a la documentaci√≥n en: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

## üìà Pr√≥ximos Pasos
*   Implementaci√≥n de **Filtrado Colaborativo Profundo** (Deep Learning) para personalizaci√≥n avanzada.
*   Contenerizaci√≥n de la API mediante **Docker**.
*   Configuraci√≥n de un pipeline de CI/CD para el despliegue autom√°tico.

---
*Autor: Gogol Andr√©s*
